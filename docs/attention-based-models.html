<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Attention-based models | sits: Satellite Image Time Series Analysis on Earth Observation Data Cubes" />
<meta property="og:type" content="book" />
<meta property="og:image" content="/images/cover_sits_book.png" />
<meta property="og:description" content="This book presents sits, an open-source R package for satellite image time series analysis. The package supports the application of machine learning techniques for classifying image time series obtained from Earth observation data cubes." />


<meta name="author" content="Gilberto Camara" />
<meta name="author" content="Rolf Simoes" />
<meta name="author" content="Felipe Souza" />
<meta name="author" content="Charlotte Peletier" />
<meta name="author" content="Alber Sanchez" />
<meta name="author" content="Pedro R. Andrade" />
<meta name="author" content="Karine Ferreira" />
<meta name="author" content="Gilberto Queiroz" />

<meta name="date" content="2022-07-15" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="This book presents sits, an open-source R package for satellite image time series analysis. The package supports the application of machine learning techniques for classifying image time series obtained from Earth observation data cubes.">

<title>Attention-based models | sits: Satellite Image Time Series Analysis on Earth Observation Data Cubes</title>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#preface">Preface</a>
<ul>
<li><a href="who-this-book-is-for.html#who-this-book-is-for">Who this book is for</a></li>
<li><a href="main-reference-for-sits.html#main-reference-for-sits">Main reference for sits</a></li>
</ul></li>
<li class="has-sub"><a href="setup.html#setup">Setup</a>
<ul>
<li><a href="support-for-gdal-and-proj.html#support-for-gdal-and-proj">Support for GDAL and PROJ</a></li>
<li><a href="installing-the-sits-package.html#installing-the-sits-package">Installing the <code>sits</code> package</a></li>
</ul></li>
<li class="has-sub"><a href="acknowledgements.html#acknowledgements">Acknowledgements</a>
<ul>
<li><a href="funding-sources.html#funding-sources">Funding Sources</a></li>
<li><a href="community-contributions.html#community-contributions">Community Contributions</a></li>
<li><a href="reproducible-papers-used-in-building-sits.html#reproducible-papers-used-in-building-sits">Reproducible papers used in building sits</a></li>
<li><a href="publications-using-sits.html#publications-using-sits">Publications using sits</a></li>
</ul></li>
<li class="has-sub"><a href="1-introduction-to-sits.html#introduction-to-sits"><span class="toc-section-number">1</span> Introduction to SITS</a>
<ul>
<li><a href="how-sits-works.html#how-sits-works">How <code>sits</code> works</a></li>
<li><a href="creating-a-data-cube.html#creating-a-data-cube">Creating a Data Cube</a></li>
<li><a href="the-time-series-table.html#the-time-series-table">The time series table</a></li>
<li><a href="training-a-machine-learning-model.html#training-a-machine-learning-model">Training a machine learning model</a></li>
<li><a href="data-cube-classification.html#data-cube-classification">Data cube classification</a></li>
<li><a href="spatial-smoothing.html#spatial-smoothing">Spatial smoothing</a></li>
<li><a href="labelling-a-probability-data-cube.html#labelling-a-probability-data-cube">Labelling a probability data cube</a></li>
<li><a href="final-remarks.html#final-remarks">Final remarks</a></li>
</ul></li>
<li class="has-sub"><a href="2-earth-observation-data-cubes.html#earth-observation-data-cubes"><span class="toc-section-number">2</span> Earth observation data cubes</a>
<ul>
<li><a href="analysis-ready-data-image-collections.html#analysis-ready-data-image-collections">Analysis-ready data image collections</a></li>
<li><a href="ard-image-collections-handled-by-sits.html#ard-image-collections-handled-by-sits">ARD image collections handled by sits</a></li>
<li><a href="regular-image-data-cubes.html#regular-image-data-cubes">Regular image data cubes</a></li>
<li><a href="creating-data-cubes.html#creating-data-cubes">Creating data cubes</a></li>
<li><a href="assessing-amazon-web-services.html#assessing-amazon-web-services">Assessing Amazon Web Services</a></li>
<li><a href="assessing-microsofts-planetary-computer.html#assessing-microsofts-planetary-computer">Assessing Microsoft’s Planetary Computer</a></li>
<li><a href="assessing-digital-earth-africa.html#assessing-digital-earth-africa">Assessing Digital Earth Africa</a></li>
<li><a href="assessing-the-brazil-data-cube.html#assessing-the-brazil-data-cube">Assessing the Brazil Data Cube</a></li>
<li><a href="defining-a-data-cube-using-ard-local-files.html#defining-a-data-cube-using-ard-local-files">Defining a data cube using ARD local files</a></li>
<li><a href="defining-a-data-cube-using-classified-images.html#defining-a-data-cube-using-classified-images">Defining a data cube using classified images</a></li>
<li><a href="regularizing-data-cubes.html#regularizing-data-cubes">Regularizing data cubes</a></li>
<li><a href="mathematical-operations-on-regular-data-cubes.html#mathematical-operations-on-regular-data-cubes">Mathematical operations on regular data cubes</a></li>
</ul></li>
<li class="has-sub"><a href="3-working-with-time-series.html#working-with-time-series"><span class="toc-section-number">3</span> Working with time series</a>
<ul>
<li><a href="data-structures-for-satellite-time-series.html#data-structures-for-satellite-time-series">Data structures for satellite time series</a></li>
<li><a href="utilities-for-handling-time-series.html#utilities-for-handling-time-series">Utilities for handling time series</a></li>
<li><a href="time-series-visualisation.html#time-series-visualisation">Time series visualisation</a></li>
<li><a href="obtaining-time-series-data-from-data-cubes.html#obtaining-time-series-data-from-data-cubes">Obtaining time series data from data cubes</a></li>
<li class="has-sub"><a href="filtering-techniques-for-time-series.html#filtering-techniques-for-time-series">Filtering techniques for time series</a>
<ul>
<li><a href="filtering-techniques-for-time-series.html#savitzkygolay-filter">Savitzky–Golay filter</a></li>
<li><a href="filtering-techniques-for-time-series.html#whittaker-filter">Whittaker filter</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="4-improving-the-quality-of-training-samples.html#improving-the-quality-of-training-samples"><span class="toc-section-number">4</span> Improving the Quality of Training Samples</a>
<ul>
<li><a href="introduction.html#introduction">Introduction</a></li>
<li><a href="hierachical-clustering-for-sample-quality-control.html#hierachical-clustering-for-sample-quality-control">Hierachical clustering for sample quality control</a></li>
<li class="has-sub"><a href="using-self-organizing-maps-for-sample-quality-control.html#using-self-organizing-maps-for-sample-quality-control">Using self-organizing maps for sample quality control</a>
<ul>
<li><a href="using-self-organizing-maps-for-sample-quality-control.html#som-based-quality-assessment-creating-the-som-map">SOM-based quality assessment: creating the SOM map</a></li>
<li><a href="using-self-organizing-maps-for-sample-quality-control.html#som-based-quality-assessment-measuring-confusion-between-labels">SOM-based quality assessment: measuring confusion between labels</a></li>
<li><a href="using-self-organizing-maps-for-sample-quality-control.html#som-based-quality-assessment-part-3-using-probabilities-to-detect-noisy-samples">SOM-based quality assessment part 3: using probabilities to detect noisy samples</a></li>
</ul></li>
<li><a href="reducing-sample-imbalance.html#reducing-sample-imbalance">Reducing sample imbalance</a></li>
<li><a href="conclusion.html#conclusion">Conclusion</a></li>
</ul></li>
<li class="has-sub"><a href="5-machine-learning-for-data-cubes-using-the-sits-package.html#machine-learning-for-data-cubes-using-the-sits-package"><span class="toc-section-number">5</span> Machine Learning for Data Cubes using the SITS package</a>
<ul>
<li><a href="machine-learning-classification.html#machine-learning-classification">Machine learning classification</a></li>
<li><a href="visualizing-sample-patterns.html#visualizing-sample-patterns">Visualizing Sample Patterns</a></li>
<li><a href="common-interface-to-machine-learning-and-deep-learning-models.html#common-interface-to-machine-learning-and-deep-learning-models">Common interface to machine learning and deep learning models</a></li>
<li><a href="random-forests.html#random-forests">Random forests</a></li>
<li><a href="support-vector-machines.html#support-vector-machines">Support Vector Machines</a></li>
<li><a href="extreme-gradient-boosting.html#extreme-gradient-boosting">Extreme Gradient Boosting</a></li>
<li><a href="deep-learning-using-multilayer-perceptrons.html#deep-learning-using-multilayer-perceptrons">Deep learning using multilayer perceptrons</a></li>
<li><a href="temporal-convolutional-neural-network-tempcnn.html#temporal-convolutional-neural-network-tempcnn">Temporal Convolutional Neural Network (TempCNN)</a></li>
<li><a href="residual-1d-cnn-networks-resnet.html#residual-1d-cnn-networks-resnet">Residual 1D CNN Networks (ResNet)</a></li>
<li><a href="attention-based-models.html#attention-based-models">Attention-based models</a></li>
<li><a href="model-tuning.html#model-tuning">Model tuning</a></li>
<li><a href="considerations-on-model-choice.html#considerations-on-model-choice">Considerations on model choice</a></li>
</ul></li>
<li class="has-sub"><a href="classification-of-images-in-data-cubes-using-satellite-image-time-series.html#classification-of-images-in-data-cubes-using-satellite-image-time-series">Classification of Images in Data Cubes using Satellite Image Time Series</a>
<ul>
<li><a href="training-the-classification-model.html#training-the-classification-model">Training the classification model</a></li>
<li><a href="building-the-data-cube.html#building-the-data-cube">Building the data cube</a></li>
<li><a href="classification-using-parallel-processing.html#classification-using-parallel-processing">Classification using parallel processing</a></li>
<li class="has-sub"><a href="post-classification-smoothing.html#post-classification-smoothing">Post-classification smoothing</a>
<ul>
<li><a href="post-classification-smoothing.html#bayesian-smoothing">Bayesian smoothing</a></li>
</ul></li>
<li class="has-sub"><a href="bilateral-smoothing.html#bilateral-smoothing">Bilateral smoothing</a>
<ul>
<li><a href="bilateral-smoothing.html#how-parallel-processing-works-in-sits"><span class="toc-section-number">5.0.1</span> How parallel processing works in <code class="unnumbered">sits</code></a></li>
<li><a href="bilateral-smoothing.html#processing-time-estimates">Processing time estimates</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="6-validation-and-accuracy-measurements-in-sits.html#validation-and-accuracy-measurements-in-sits"><span class="toc-section-number">6</span> Validation and accuracy measurements in SITS</a>
<ul>
<li><a href="6.1-case-study-used-in-this-chapter.html#case-study-used-in-this-chapter"><span class="toc-section-number">6.1</span> Case study used in this Chapter</a></li>
<li><a href="6.2-validation-techniques.html#validation-techniques"><span class="toc-section-number">6.2</span> Validation techniques</a></li>
<li><a href="6.3-comparing-different-machine-learning-methods-using-k-fold-validation.html#comparing-different-machine-learning-methods-using-k-fold-validation"><span class="toc-section-number">6.3</span> Comparing different machine learning methods using k-fold validation</a></li>
<li class="has-sub"><a href="6.4-accuracy-assessment.html#accuracy-assessment"><span class="toc-section-number">6.4</span> Accuracy assessment</a>
<ul>
<li><a href="6.4-accuracy-assessment.html#time-series"><span class="toc-section-number">6.4.1</span> Time series</a></li>
<li><a href="6.4-accuracy-assessment.html#classified-images"><span class="toc-section-number">6.4.2</span> Classified images</a></li>
</ul></li>
</ul></li>
<li><a href="uncertainty-and-active-learning.html#uncertainty-and-active-learning">Uncertainty and active learning</a></li>
<li class="has-sub"><a href="7-design-and-extensibility-considerations.html#design-and-extensibility-considerations"><span class="toc-section-number">7</span> Design and extensibility considerations</a>
<ul>
<li><a href="7.1-design-decisions.html#design-decisions"><span class="toc-section-number">7.1</span> Design decisions</a></li>
</ul></li>
<li class="has-sub"><a href="technical-annex.html#technical-annex">Technical Annex</a>
<ul>
<li class="has-sub"><a href="7.2-bayesian-smoothing-1.html#bayesian-smoothing-1"><span class="toc-section-number">7.2</span> Bayesian smoothing</a>
<ul>
<li><a href="7.2-bayesian-smoothing-1.html#derivation-of-bayesian-parameters-for-spatiotemporal-smoothing"><span class="toc-section-number">7.2.1</span> Derivation of bayesian parameters for spatiotemporal smoothing</a></li>
</ul></li>
<li><a href="7.3-bilateral-smoothing-1.html#bilateral-smoothing-1"><span class="toc-section-number">7.3</span> Bilateral smoothing</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="attention-based-models" class="section level2 unnumbered">
<h2>Attention-based models</h2>
<p>Attention-based models have become one of the most used deep learning architectures for problems that involve sequential data inputs, e.g., text recognition and automatic translation. The general idea is that in applications such as language translation not all inputs are alike. Consider the English sentence <em>“Look at all the lonely people”</em> and its Portuguese translation <em>“Olhe para todas as pessoas solitárias”</em>. A good translation system needs to relate the words “look” and “people” as the key parts of this sentence and to ensure such link is captured in the translation. A specific type of attention models, called <em>transformers</em>, enables the recognition of such complex relationships between input and output sequences <span class="citation"><a href="#ref-Vaswani2017" role="doc-biblioref">[51]</a></span>.</p>
<p>The basic structure of transformers is the same as other neural network algorithms. They have an encoder that transforms the input textual values into numerical vectors, and a decoder that processes these vectors and provides suitable answers. The difference is on how the values are handled internally. In multilayer perceptrons (MLP), all inputs are treated equally at first; based on iterative matching of training and test data, the backpropagation technique feeds information back to the initial layers to identify the most relevant combination of inputs that produces the best output. In convolutional nets (CNN), input values that are close in time (1D) or space (2D) are combined to produce higher-level information that helps to distinguish the different components of the input data. For text recognition, the initial choice of deep learning studies was to use recurrent neural networks (RNN) that handle input sequences sequentially. However, neither MLPs, nor CNNs or RNNs have been able to capture the structure of complex inputs such as natural language. The success of transformer-based solutions accounts for substantial improvements in natural language processing.</p>
<p>The two main differences between transformer models and other algorithms are the use of positional encoding and self-attention. Positional encoding assigns an index to each input value which ensures that the relative locations of the inputs are maintained throughout the learning and processing phases. Self-attention works by comparing every word in the sentence to every other word in the sentence, including itself. In this way, it learns contextual information about the relation between the words. This conception has been validated in large language models such as BERT <span class="citation"><a href="#ref-Devlin2019" role="doc-biblioref">[52]</a></span> and GPT-3 <span class="citation"><a href="#ref-Brown2020" role="doc-biblioref">[53]</a></span>.</p>
<p>The application of attention-based models for satellite image time series analysis is proposed by Garnot et <span class="citation"><a href="#ref-Garnot2020a" role="doc-biblioref">[31]</a></span> and Russwurm and Körner <span class="citation"><a href="#ref-Russwurm2020" role="doc-biblioref">[32]</a></span>. The intuition behind the use of self-attention to image time series is to identify which observations are most relevant for classification. The first model proposed by Garnot and co-authors was a full transformer-based model <span class="citation"><a href="#ref-Garnot2020a" role="doc-biblioref">[31]</a></span>. Considering that image time series classification is a easier task that natural language processing, Garnot et al <span class="citation"><a href="#ref-Garnot2020b" role="doc-biblioref">[54]</a></span> also propose a simplified version of the full transformer model. This simpler model uses a reduced way to compute the attention matrix, reducing time for training and classification without loss of quality of result.</p>
<p>In <code>sits</code>, the full transformer-based model proposed by Garnot and co-authors <span class="citation"><a href="#ref-Garnot2020a" role="doc-biblioref">[31]</a></span> is implemented using the <code>sits_tae()</code> function. The default parameters are those proposed by the authors. The default optimizer is the same is <code>optim_adamw</code>, available in package <code>torchopt</code>.</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="attention-based-models.html#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># train a machine learning model using TAE</span></span>
<span id="cb76-2"><a href="attention-based-models.html#cb76-2" aria-hidden="true" tabindex="-1"></a>tae_model <span class="ot">&lt;-</span> <span class="fu">sits_train</span>(</span>
<span id="cb76-3"><a href="attention-based-models.html#cb76-3" aria-hidden="true" tabindex="-1"></a>  samples_matogrosso_mod13q1,</span>
<span id="cb76-4"><a href="attention-based-models.html#cb76-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sits_tae</span>(</span>
<span id="cb76-5"><a href="attention-based-models.html#cb76-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs               =</span> <span class="dv">150</span>,</span>
<span id="cb76-6"><a href="attention-based-models.html#cb76-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size           =</span> <span class="dv">64</span>,</span>
<span id="cb76-7"><a href="attention-based-models.html#cb76-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer            =</span> torchopt<span class="sc">::</span>optim_adamw,</span>
<span id="cb76-8"><a href="attention-based-models.html#cb76-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split     =</span> <span class="fl">0.2</span>,</span>
<span id="cb76-9"><a href="attention-based-models.html#cb76-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose              =</span> <span class="cn">FALSE</span></span>
<span id="cb76-10"><a href="attention-based-models.html#cb76-10" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb76-11"><a href="attention-based-models.html#cb76-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb76-12"><a href="attention-based-models.html#cb76-12" aria-hidden="true" tabindex="-1"></a><span class="co"># show training evolution</span></span>
<span id="cb76-13"><a href="attention-based-models.html#cb76-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tae_model)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="sitsbook_files/figure-html/unnamed-chunk-84-1.png" alt="Training evolution of Temporal Self-Attention model." width="70%" />
<p class="caption">
Training evolution of Temporal Self-Attention model.
</p>
</div>
<p>Then, we classify a 16-year time series using the TAE model.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="attention-based-models.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Classify using DL model and plot the result</span></span>
<span id="cb77-2"><a href="attention-based-models.html#cb77-2" aria-hidden="true" tabindex="-1"></a>class <span class="ot">&lt;-</span> point_mt_6bands <span class="sc">%&gt;%</span></span>
<span id="cb77-3"><a href="attention-based-models.html#cb77-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sits_select</span>(<span class="at">bands =</span> <span class="fu">c</span>(<span class="st">&quot;NDVI&quot;</span>, <span class="st">&quot;EVI&quot;</span>, <span class="st">&quot;NIR&quot;</span>, <span class="st">&quot;MIR&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb77-4"><a href="attention-based-models.html#cb77-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sits_classify</span>(tae_model) <span class="sc">%&gt;%</span></span>
<span id="cb77-5"><a href="attention-based-models.html#cb77-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="at">bands =</span> <span class="fu">c</span>(<span class="st">&quot;NDVI&quot;</span>, <span class="st">&quot;EVI&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="sitsbook_files/figure-html/unnamed-chunk-85-1.png" alt="Classification of time series using TAE." width="70%" />
<p class="caption">
Classification of time series using TAE.
</p>
</div>
<p>In <code>sits</code>, the simplified transformer-based model proposed by Garnot and co-authors <span class="citation"><a href="#ref-Garnot2020a" role="doc-biblioref">[31]</a></span> is implemented using the <code>sits_lighttae()</code> function. The default optimizer is the same is <code>optim_adamw</code>, available in package <code>torchopt</code>. The most important parameter to be set is the learning rate <code>lr</code>. Values ranging from 0.001 to 0.005 should produce reasonable results. See also the section below on model tuning.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="attention-based-models.html#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># train a machine learning model using TAE</span></span>
<span id="cb78-2"><a href="attention-based-models.html#cb78-2" aria-hidden="true" tabindex="-1"></a>ltae_model <span class="ot">&lt;-</span> <span class="fu">sits_train</span>(</span>
<span id="cb78-3"><a href="attention-based-models.html#cb78-3" aria-hidden="true" tabindex="-1"></a>  samples_matogrosso_mod13q1,</span>
<span id="cb78-4"><a href="attention-based-models.html#cb78-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sits_lighttae</span>(</span>
<span id="cb78-5"><a href="attention-based-models.html#cb78-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> <span class="dv">150</span>,</span>
<span id="cb78-6"><a href="attention-based-models.html#cb78-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> <span class="dv">64</span>,</span>
<span id="cb78-7"><a href="attention-based-models.html#cb78-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> torchopt<span class="sc">::</span>optim_adamw,</span>
<span id="cb78-8"><a href="attention-based-models.html#cb78-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">opt_hparams =</span> <span class="fu">list</span>(<span class="at">lr =</span> <span class="fl">0.001</span>),</span>
<span id="cb78-9"><a href="attention-based-models.html#cb78-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> <span class="fl">0.2</span></span>
<span id="cb78-10"><a href="attention-based-models.html#cb78-10" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb78-11"><a href="attention-based-models.html#cb78-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-12"><a href="attention-based-models.html#cb78-12" aria-hidden="true" tabindex="-1"></a><span class="co"># show training evolution</span></span>
<span id="cb78-13"><a href="attention-based-models.html#cb78-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ltae_model)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="sitsbook_files/figure-html/unnamed-chunk-86-1.png" alt="Training evolution of Lightweight Temporal Self-Attention model." width="70%" />
<p class="caption">
Training evolution of Lightweight Temporal Self-Attention model.
</p>
</div>
<p>Then, we classify a 16-year time series using the LightTAE model.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="attention-based-models.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Classify using DL model and plot the result</span></span>
<span id="cb79-2"><a href="attention-based-models.html#cb79-2" aria-hidden="true" tabindex="-1"></a>class <span class="ot">&lt;-</span> point_mt_6bands <span class="sc">%&gt;%</span></span>
<span id="cb79-3"><a href="attention-based-models.html#cb79-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sits_select</span>(<span class="at">bands =</span> <span class="fu">c</span>(<span class="st">&quot;NDVI&quot;</span>, <span class="st">&quot;EVI&quot;</span>, <span class="st">&quot;NIR&quot;</span>, <span class="st">&quot;MIR&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb79-4"><a href="attention-based-models.html#cb79-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sits_classify</span>(ltae_model) <span class="sc">%&gt;%</span></span>
<span id="cb79-5"><a href="attention-based-models.html#cb79-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="at">bands =</span> <span class="fu">c</span>(<span class="st">&quot;NDVI&quot;</span>, <span class="st">&quot;EVI&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="sitsbook_files/figure-html/unnamed-chunk-87-1.png" alt="Classification of time series using LightTAE." width="70%" />
<p class="caption">
Classification of time series using LightTAE.
</p>
</div>
<div style="page-break-after: always;"></div>
<p>The behaviour of both <code>sits_tae()</code> and <code>sits_lighttae()</code> is similar to that of <code>sits_tempcnn()</code>. It points out the possible need for more classes and training data to better represent the transition period between 2004 and 2010. One possibility is that the training data associated to the Pasture class is only consistent with the time series between the years 2005 to 2008. However, the transition from Forest to Pasture in 2004 and from Pasture to Agriculture in 2009-2010 is subject to uncertainty, since the classifiers do not agree on the resulting classes. In general, the deep learning temporal-aware models are more sensitive to class variability than random forests and extreme gradient boosters.</p>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body">
<div id="ref-Garnot2020a" class="csl-entry">
<div class="csl-left-margin">[31] </div><div class="csl-right-inline">V. Garnot, L. Landrieu, S. Giordano, and N. Chehata, <span>“Satellite <span>Image Time Series Classification With Pixel-Set Encoders</span> and <span>Temporal Self-Attention</span>,”</span> in <em>2020 <span>IEEE</span>/<span>CVF Conference</span> on <span>Computer Vision</span> and <span>Pattern Recognition</span> (<span>CVPR</span>)</em>, 2020, pp. 12322–12331, doi: <a href="https://doi.org/10.1109/CVPR42600.2020.01234">10.1109/CVPR42600.2020.01234</a>.</div>
</div>
<div id="ref-Russwurm2020" class="csl-entry">
<div class="csl-left-margin">[32] </div><div class="csl-right-inline">M. Rußwurm, C. Pelletier, M. Zollner, S. Lefèvre, and M. Körner, <span>“<span>BreizhCrops</span>: <span>A Time Series Dataset</span> for <span>Crop Type Mapping</span>,”</span> 2020.</div>
</div>
<div id="ref-Vaswani2017" class="csl-entry">
<div class="csl-left-margin">[51] </div><div class="csl-right-inline">A. Vaswani <em>et al.</em>, <span>“Attention is <span>All</span> you <span>Need</span>,”</span> in <em>Advances in <span>Neural Information Processing Systems</span></em>, 2017, vol. 30.</div>
</div>
<div id="ref-Devlin2019" class="csl-entry">
<div class="csl-left-margin">[52] </div><div class="csl-right-inline">J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, <span>“<span>BERT</span>: <span class="nocase">Pre-training</span> of <span>Deep Bidirectional Transformers</span> for <span>Language Understanding</span>.”</span> <span>arXiv</span>, 2019, doi: <a href="https://doi.org/10.48550/arXiv.1810.04805">10.48550/arXiv.1810.04805</a>.</div>
</div>
<div id="ref-Brown2020" class="csl-entry">
<div class="csl-left-margin">[53] </div><div class="csl-right-inline">T. B. Brown <em>et al.</em>, <span>“Language <span>Models</span> are <span>Few-Shot Learners</span>.”</span> <span>arXiv</span>, 2020, doi: <a href="https://doi.org/10.48550/arXiv.2005.14165">10.48550/arXiv.2005.14165</a>.</div>
</div>
<div id="ref-Garnot2020b" class="csl-entry">
<div class="csl-left-margin">[54] </div><div class="csl-right-inline">V. S. F. Garnot and L. Landrieu, <span>“Lightweight <span class="nocase">Temporal Self-attention</span> for <span>Classifying Satellite Images Time Series</span>,”</span> in <em>Advanced <span>Analytics</span> and <span>Learning</span> on <span>Temporal Data</span></em>, 2020, pp. 171–181, doi: <a href="https://doi.org/10.1007/978-3-030-65742-0_12">10.1007/978-3-030-65742-0_12</a>.</div>
</div>
</div>
<p style="text-align: center;">
<a href="residual-1d-cnn-networks-resnet.html"><button class="btn btn-default">Previous</button></a>
<a href="model-tuning.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
