<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Deep learning using multilayer perceptrons | sits: Satellite Image Time Series Analysis on Earth Observation Data Cubes" />
<meta property="og:type" content="book" />
<meta property="og:image" content="/images/cover_sits_book.png" />
<meta property="og:description" content="This book presents sits, an open-source R package for satellite image time series analysis. The package supports the application of machine learning techniques for classifying image time series obtained from Earth observation data cubes." />


<meta name="author" content="Gilberto Camara" />
<meta name="author" content="Rolf Simoes" />
<meta name="author" content="Felipe Souza" />
<meta name="author" content="Charlotte Peletier" />
<meta name="author" content="Alber Sanchez" />
<meta name="author" content="Pedro R. Andrade" />
<meta name="author" content="Karine Ferreira" />
<meta name="author" content="Gilberto Queiroz" />

<meta name="date" content="2022-07-15" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="This book presents sits, an open-source R package for satellite image time series analysis. The package supports the application of machine learning techniques for classifying image time series obtained from Earth observation data cubes.">

<title>Deep learning using multilayer perceptrons | sits: Satellite Image Time Series Analysis on Earth Observation Data Cubes</title>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#preface">Preface</a>
<ul>
<li><a href="who-this-book-is-for.html#who-this-book-is-for">Who this book is for</a></li>
<li><a href="main-reference-for-sits.html#main-reference-for-sits">Main reference for sits</a></li>
</ul></li>
<li class="has-sub"><a href="setup.html#setup">Setup</a>
<ul>
<li><a href="support-for-gdal-and-proj.html#support-for-gdal-and-proj">Support for GDAL and PROJ</a></li>
<li><a href="installing-the-sits-package.html#installing-the-sits-package">Installing the <code>sits</code> package</a></li>
</ul></li>
<li class="has-sub"><a href="acknowledgements.html#acknowledgements">Acknowledgements</a>
<ul>
<li><a href="funding-sources.html#funding-sources">Funding Sources</a></li>
<li><a href="community-contributions.html#community-contributions">Community Contributions</a></li>
<li><a href="reproducible-papers-used-in-building-sits.html#reproducible-papers-used-in-building-sits">Reproducible papers used in building sits</a></li>
<li><a href="publications-using-sits.html#publications-using-sits">Publications using sits</a></li>
</ul></li>
<li class="has-sub"><a href="1-introduction-to-sits.html#introduction-to-sits"><span class="toc-section-number">1</span> Introduction to SITS</a>
<ul>
<li><a href="how-sits-works.html#how-sits-works">How <code>sits</code> works</a></li>
<li><a href="creating-a-data-cube.html#creating-a-data-cube">Creating a Data Cube</a></li>
<li><a href="the-time-series-table.html#the-time-series-table">The time series table</a></li>
<li><a href="training-a-machine-learning-model.html#training-a-machine-learning-model">Training a machine learning model</a></li>
<li><a href="data-cube-classification.html#data-cube-classification">Data cube classification</a></li>
<li><a href="spatial-smoothing.html#spatial-smoothing">Spatial smoothing</a></li>
<li><a href="labelling-a-probability-data-cube.html#labelling-a-probability-data-cube">Labelling a probability data cube</a></li>
<li><a href="final-remarks.html#final-remarks">Final remarks</a></li>
</ul></li>
<li class="has-sub"><a href="2-earth-observation-data-cubes.html#earth-observation-data-cubes"><span class="toc-section-number">2</span> Earth observation data cubes</a>
<ul>
<li><a href="analysis-ready-data-image-collections.html#analysis-ready-data-image-collections">Analysis-ready data image collections</a></li>
<li><a href="ard-image-collections-handled-by-sits.html#ard-image-collections-handled-by-sits">ARD image collections handled by sits</a></li>
<li><a href="regular-image-data-cubes.html#regular-image-data-cubes">Regular image data cubes</a></li>
<li><a href="creating-data-cubes.html#creating-data-cubes">Creating data cubes</a></li>
<li><a href="assessing-amazon-web-services.html#assessing-amazon-web-services">Assessing Amazon Web Services</a></li>
<li><a href="assessing-microsofts-planetary-computer.html#assessing-microsofts-planetary-computer">Assessing Microsoft’s Planetary Computer</a></li>
<li><a href="assessing-digital-earth-africa.html#assessing-digital-earth-africa">Assessing Digital Earth Africa</a></li>
<li><a href="assessing-the-brazil-data-cube.html#assessing-the-brazil-data-cube">Assessing the Brazil Data Cube</a></li>
<li><a href="defining-a-data-cube-using-ard-local-files.html#defining-a-data-cube-using-ard-local-files">Defining a data cube using ARD local files</a></li>
<li><a href="defining-a-data-cube-using-classified-images.html#defining-a-data-cube-using-classified-images">Defining a data cube using classified images</a></li>
<li><a href="regularizing-data-cubes.html#regularizing-data-cubes">Regularizing data cubes</a></li>
<li><a href="mathematical-operations-on-regular-data-cubes.html#mathematical-operations-on-regular-data-cubes">Mathematical operations on regular data cubes</a></li>
</ul></li>
<li class="has-sub"><a href="3-working-with-time-series.html#working-with-time-series"><span class="toc-section-number">3</span> Working with time series</a>
<ul>
<li><a href="data-structures-for-satellite-time-series.html#data-structures-for-satellite-time-series">Data structures for satellite time series</a></li>
<li><a href="utilities-for-handling-time-series.html#utilities-for-handling-time-series">Utilities for handling time series</a></li>
<li><a href="time-series-visualisation.html#time-series-visualisation">Time series visualisation</a></li>
<li><a href="obtaining-time-series-data-from-data-cubes.html#obtaining-time-series-data-from-data-cubes">Obtaining time series data from data cubes</a></li>
<li class="has-sub"><a href="filtering-techniques-for-time-series.html#filtering-techniques-for-time-series">Filtering techniques for time series</a>
<ul>
<li><a href="filtering-techniques-for-time-series.html#savitzkygolay-filter">Savitzky–Golay filter</a></li>
<li><a href="filtering-techniques-for-time-series.html#whittaker-filter">Whittaker filter</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="4-improving-the-quality-of-training-samples.html#improving-the-quality-of-training-samples"><span class="toc-section-number">4</span> Improving the Quality of Training Samples</a>
<ul>
<li><a href="introduction.html#introduction">Introduction</a></li>
<li><a href="hierachical-clustering-for-sample-quality-control.html#hierachical-clustering-for-sample-quality-control">Hierachical clustering for sample quality control</a></li>
<li class="has-sub"><a href="using-self-organizing-maps-for-sample-quality-control.html#using-self-organizing-maps-for-sample-quality-control">Using self-organizing maps for sample quality control</a>
<ul>
<li><a href="using-self-organizing-maps-for-sample-quality-control.html#som-based-quality-assessment-creating-the-som-map">SOM-based quality assessment: creating the SOM map</a></li>
<li><a href="using-self-organizing-maps-for-sample-quality-control.html#som-based-quality-assessment-measuring-confusion-between-labels">SOM-based quality assessment: measuring confusion between labels</a></li>
<li><a href="using-self-organizing-maps-for-sample-quality-control.html#som-based-quality-assessment-part-3-using-probabilities-to-detect-noisy-samples">SOM-based quality assessment part 3: using probabilities to detect noisy samples</a></li>
</ul></li>
<li><a href="reducing-sample-imbalance.html#reducing-sample-imbalance">Reducing sample imbalance</a></li>
<li><a href="conclusion.html#conclusion">Conclusion</a></li>
</ul></li>
<li class="has-sub"><a href="5-machine-learning-for-data-cubes-using-the-sits-package.html#machine-learning-for-data-cubes-using-the-sits-package"><span class="toc-section-number">5</span> Machine Learning for Data Cubes using the SITS package</a>
<ul>
<li><a href="machine-learning-classification.html#machine-learning-classification">Machine learning classification</a></li>
<li><a href="visualizing-sample-patterns.html#visualizing-sample-patterns">Visualizing Sample Patterns</a></li>
<li><a href="common-interface-to-machine-learning-and-deep-learning-models.html#common-interface-to-machine-learning-and-deep-learning-models">Common interface to machine learning and deep learning models</a></li>
<li><a href="random-forests.html#random-forests">Random forests</a></li>
<li><a href="support-vector-machines.html#support-vector-machines">Support Vector Machines</a></li>
<li><a href="extreme-gradient-boosting.html#extreme-gradient-boosting">Extreme Gradient Boosting</a></li>
<li><a href="deep-learning-using-multilayer-perceptrons.html#deep-learning-using-multilayer-perceptrons">Deep learning using multilayer perceptrons</a></li>
<li><a href="temporal-convolutional-neural-network-tempcnn.html#temporal-convolutional-neural-network-tempcnn">Temporal Convolutional Neural Network (TempCNN)</a></li>
<li><a href="residual-1d-cnn-networks-resnet.html#residual-1d-cnn-networks-resnet">Residual 1D CNN Networks (ResNet)</a></li>
<li><a href="attention-based-models.html#attention-based-models">Attention-based models</a></li>
<li><a href="model-tuning.html#model-tuning">Model tuning</a></li>
<li><a href="considerations-on-model-choice.html#considerations-on-model-choice">Considerations on model choice</a></li>
</ul></li>
<li class="has-sub"><a href="classification-of-images-in-data-cubes-using-satellite-image-time-series.html#classification-of-images-in-data-cubes-using-satellite-image-time-series">Classification of Images in Data Cubes using Satellite Image Time Series</a>
<ul>
<li><a href="training-the-classification-model.html#training-the-classification-model">Training the classification model</a></li>
<li><a href="building-the-data-cube.html#building-the-data-cube">Building the data cube</a></li>
<li><a href="classification-using-parallel-processing.html#classification-using-parallel-processing">Classification using parallel processing</a></li>
<li class="has-sub"><a href="post-classification-smoothing.html#post-classification-smoothing">Post-classification smoothing</a>
<ul>
<li><a href="post-classification-smoothing.html#bayesian-smoothing">Bayesian smoothing</a></li>
</ul></li>
<li class="has-sub"><a href="bilateral-smoothing.html#bilateral-smoothing">Bilateral smoothing</a>
<ul>
<li><a href="bilateral-smoothing.html#how-parallel-processing-works-in-sits"><span class="toc-section-number">5.0.1</span> How parallel processing works in <code class="unnumbered">sits</code></a></li>
<li><a href="bilateral-smoothing.html#processing-time-estimates">Processing time estimates</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="6-validation-and-accuracy-measurements-in-sits.html#validation-and-accuracy-measurements-in-sits"><span class="toc-section-number">6</span> Validation and accuracy measurements in SITS</a>
<ul>
<li><a href="6.1-case-study-used-in-this-chapter.html#case-study-used-in-this-chapter"><span class="toc-section-number">6.1</span> Case study used in this Chapter</a></li>
<li><a href="6.2-validation-techniques.html#validation-techniques"><span class="toc-section-number">6.2</span> Validation techniques</a></li>
<li><a href="6.3-comparing-different-machine-learning-methods-using-k-fold-validation.html#comparing-different-machine-learning-methods-using-k-fold-validation"><span class="toc-section-number">6.3</span> Comparing different machine learning methods using k-fold validation</a></li>
<li class="has-sub"><a href="6.4-accuracy-assessment.html#accuracy-assessment"><span class="toc-section-number">6.4</span> Accuracy assessment</a>
<ul>
<li><a href="6.4-accuracy-assessment.html#time-series"><span class="toc-section-number">6.4.1</span> Time series</a></li>
<li><a href="6.4-accuracy-assessment.html#classified-images"><span class="toc-section-number">6.4.2</span> Classified images</a></li>
</ul></li>
</ul></li>
<li><a href="uncertainty-and-active-learning.html#uncertainty-and-active-learning">Uncertainty and active learning</a></li>
<li class="has-sub"><a href="7-design-and-extensibility-considerations.html#design-and-extensibility-considerations"><span class="toc-section-number">7</span> Design and extensibility considerations</a>
<ul>
<li><a href="7.1-design-decisions.html#design-decisions"><span class="toc-section-number">7.1</span> Design decisions</a></li>
</ul></li>
<li class="has-sub"><a href="technical-annex.html#technical-annex">Technical Annex</a>
<ul>
<li class="has-sub"><a href="7.2-bayesian-smoothing-1.html#bayesian-smoothing-1"><span class="toc-section-number">7.2</span> Bayesian smoothing</a>
<ul>
<li><a href="7.2-bayesian-smoothing-1.html#derivation-of-bayesian-parameters-for-spatiotemporal-smoothing"><span class="toc-section-number">7.2.1</span> Derivation of bayesian parameters for spatiotemporal smoothing</a></li>
</ul></li>
<li><a href="7.3-bilateral-smoothing-1.html#bilateral-smoothing-1"><span class="toc-section-number">7.3</span> Bilateral smoothing</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="deep-learning-using-multilayer-perceptrons" class="section level2 unnumbered">
<h2>Deep learning using multilayer perceptrons</h2>
<p>To support deep learning methods, <code>sits</code> uses the <code>torch</code> R package, which takes the Facebook <code>torch</code> C++ library as a back-end. Machine learning algorithms that use the R <code>torch</code> package are similar from those developed using <code>PyTorch</code>. Converting image time series algorithms developed in <code>PyTorch</code> to be using in <code>sits</code> is straightforward. Please see the chapter on “Extensibility” for guidance on how to include new deep learning algorithms in <code>sits</code>.</p>
<p>The simplest deep learning method is multilayer perceptrons (MLPs), which are feedforward artificial neural networks. A MLP consists of three kinds of nodes: an input layer, a set of hidden layers and an output layer. The input layer has the same dimension as the number of the features in the data set. The hidden layers attempt to approximate the best classification function. The output layer makes a decision about which class should be assigned to the input.</p>
<p>In <code>sits</code>, users build MLP models using <code>sits_mlp()</code>. Since there is no established model for generic classification of satellite image time series, designing MLP models requires parameter customization. The most important decisions are the number of layers in the model and the number of neurons per layer. These values are set by the <code>layers</code> parameters, which is a list of integer values. The size of the list is the number of layers and each element of the list indicates the number of nodes per layer.</p>
<p>The choice of the number of layers depends on the inherent separability of the data set to be classified. For data sets where the classes have different signatures, a shallow model (with 3 layers) may provide appropriate responses. More complex situations require models of deeper hierarchy. The user should be aware that some models with many hidden layers may take a long time to train and may not be able to converge. The suggestion is to start with 3 layers and test different options of number of neurons per layer, before increasing the number of layers.</p>
<p>MLP models also need to include the activation function. The activation function of a node defines the output of that node given an input or set of inputs. Following standard practices <span class="citation"><a href="#ref-Goodfellow2016" role="doc-biblioref">[24]</a></span>, we use the <code>relu</code> activation function.</p>
<p>Users can also define the optimization method (<code>optimizer</code>), which defines the gradient descent algorithm to be used. These methods aim to maximize an objective function by updating the parameters in the opposite direction of the gradient of the objective function <span class="citation"><a href="#ref-Ruder2016" role="doc-biblioref">[42]</a></span>. Based on experience with image time series, we recommend that users start by using the default method provided by <code>sits</code>, which is the <code>optimizer_adamw</code> method from package <code>torchopt</code>. Please refer to the <code>torchopt</code> package for additional information.</p>
<p>Another relevant parameter is the list of dropout rates (<code>dropout</code>). Dropout is a technique for randomly dropping units from the neural network during training <span class="citation"><a href="#ref-Srivastava2014" role="doc-biblioref">[43]</a></span>. By randomly discarding some neurons, dropout reduces overfitting. Since the purpose of a cascade of neural nets is to improve learning as more data is acquired, discarding some neurons may seem a waste of resources. In practice, dropout prevents an early convergence to a local minimum <span class="citation"><a href="#ref-Goodfellow2016" role="doc-biblioref">[24]</a></span>. We suggest users experiment with different dropout rates, starting from small values (10-30%) and increasing as required.</p>
<p>The following example shows how to use <code>sits_mlp()</code>. The default parameters for have been chosen based on a modified verion of <span class="citation"><a href="#ref-Wang2017" role="doc-biblioref">[44]</a></span>, which proposes the use of multilayer perceptrons as a baseline for time series classification. These parameters are: (a) Three layers with 512 neurons each, specified by the parameter <code>layers</code>; (b) Using the “relu” activation function; (c) dropout rates of 40%, 30%, and 20% for the layers; (d) the “optimizer_adamw” as optimizer (default value); (e) a number of training steps (<code>epochs</code>) of 100; (f) a <code>batch_size</code> of 64, which indicates how many time series are used for input at a given steps; and (g) a validation percentage of 20%, which means 20% of the samples will be randomly set side for validation.</p>
<p>In our experience, if the training dataset is of good quality, using 3 to 5 layers is a reasonable compromise. Further increase on the number of layers will not improve the model. To simplify the output generation, the <code>verbose</code> option has been turned off. The default value is “on”. After the model has been generated, we plot its training history. In this and in the following examples of using deep learning classifiers, both the training samples and the point to be classified are filtered with <code>sits_whittaker()</code> with a small smoothing parameter (lambda = 0.5). Since deep learning classifiers are not as robust as Random Forest or XGBoost, the right amount of smoothing improves their detection power in case of noisy data.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># train a  model for the Mato Grosso data using an MLP model</span></span>
<span id="cb70-2"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="co"># this is an example of how to set parameters</span></span>
<span id="cb70-3"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="co"># first-time users should test default options first</span></span>
<span id="cb70-4"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-4" aria-hidden="true" tabindex="-1"></a>mlp_model <span class="ot">&lt;-</span> <span class="fu">sits_train</span>(</span>
<span id="cb70-5"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">samples =</span> samples_matogrosso_mod13q1,</span>
<span id="cb70-6"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">ml_method =</span> <span class="fu">sits_mlp</span>(</span>
<span id="cb70-7"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">layers           =</span> <span class="fu">c</span>(<span class="dv">512</span>, <span class="dv">512</span>, <span class="dv">512</span>),</span>
<span id="cb70-8"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">dropout_rates    =</span> <span class="fu">c</span>(<span class="fl">0.40</span>, <span class="fl">0.30</span>, <span class="fl">0.20</span>),</span>
<span id="cb70-9"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs           =</span> <span class="dv">100</span>,</span>
<span id="cb70-10"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size       =</span> <span class="dv">64</span>,</span>
<span id="cb70-11"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose          =</span> <span class="cn">FALSE</span>,</span>
<span id="cb70-12"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> <span class="fl">0.2</span></span>
<span id="cb70-13"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-13" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb70-14"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb70-15"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-15" aria-hidden="true" tabindex="-1"></a><span class="co"># show training evolution</span></span>
<span id="cb70-16"><a href="deep-learning-using-multilayer-perceptrons.html#cb70-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mlp_model)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="sitsbook_files/figure-html/unnamed-chunk-75-1.png" alt="Evolution of training accuracy of MLP model." width="70%" />
<p class="caption">
Evolution of training accuracy of MLP model.
</p>
</div>
<div style="page-break-after: always;"></div>
<p>Then, we classify a 16-year time series using the multilayer perceptron model.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="deep-learning-using-multilayer-perceptrons.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Classify using DL model and plot the result</span></span>
<span id="cb71-2"><a href="deep-learning-using-multilayer-perceptrons.html#cb71-2" aria-hidden="true" tabindex="-1"></a>point_mt_6bands <span class="sc">%&gt;%</span></span>
<span id="cb71-3"><a href="deep-learning-using-multilayer-perceptrons.html#cb71-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sits_select</span>(<span class="at">bands =</span> <span class="fu">c</span>(<span class="st">&quot;NDVI&quot;</span>, <span class="st">&quot;EVI&quot;</span>, <span class="st">&quot;NIR&quot;</span>, <span class="st">&quot;MIR&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb71-4"><a href="deep-learning-using-multilayer-perceptrons.html#cb71-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sits_classify</span>(mlp_model) <span class="sc">%&gt;%</span></span>
<span id="cb71-5"><a href="deep-learning-using-multilayer-perceptrons.html#cb71-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="at">bands =</span> <span class="fu">c</span>(<span class="st">&quot;NDVI&quot;</span>, <span class="st">&quot;EVI&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="sitsbook_files/figure-html/unnamed-chunk-76-1.png" alt="Classification of time series using MLP." width="70%" />
<p class="caption">
Classification of time series using MLP.
</p>
</div>
<p>In theory, multilayer perceptron model is able to capture more subtle changes than the random forests and XGBoost models. In this specific case, the result is similar to the them. Although the model mixes the “Soy_Corn” and “Soy_Millet” classes, the distinction between their temporal signatures is quite subtle. Also in this case, this suggests the need to improve the number of samples. In this examples, the MLP model shows an increase in the sensitivity compared to previous models. We recommend that the users compare different configurations, since the MLP model is sensitive to changes in its parameters.</p>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body">
<div id="ref-Goodfellow2016" class="csl-entry">
<div class="csl-left-margin">[24] </div><div class="csl-right-inline">I. Goodfellow, Y. Bengio, and A. Courville, <em>Deep <span>Learning</span></em>. <span>MIT Press</span>, 2016.</div>
</div>
<div id="ref-Ruder2016" class="csl-entry">
<div class="csl-left-margin">[42] </div><div class="csl-right-inline">S. Ruder, <span>“An overview of gradient descent optimization algorithms,”</span> <em>CoRR</em>, vol. abs/1609.04747, 2016.</div>
</div>
<div id="ref-Srivastava2014" class="csl-entry">
<div class="csl-left-margin">[43] </div><div class="csl-right-inline">N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, <span>“Dropout: <span>A</span> simple way to prevent neural networks from overfitting,”</span> <em>The Journal of Machine Learning Research</em>, vol. 15, no. 1, pp. 1929–1958, 2014.</div>
</div>
<div id="ref-Wang2017" class="csl-entry">
<div class="csl-left-margin">[44] </div><div class="csl-right-inline">Z. Wang, W. Yan, and T. Oates, <span>“Time <span>Series Classification</span> from <span>Scratch</span> with <span>Deep Neural Networks</span>: <span>A Strong Baseline</span>,”</span> 2017.</div>
</div>
</div>
<p style="text-align: center;">
<a href="extreme-gradient-boosting.html"><button class="btn btn-default">Previous</button></a>
<a href="temporal-convolutional-neural-network-tempcnn.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
