<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Temporal Convolutional Neural Network (TempCNN) | sits: Satellite Image Time Series Analysis on Earth Observation Data Cubes" />
<meta property="og:type" content="book" />
<meta property="og:image" content="/images/cover_sits_book.png" />
<meta property="og:description" content="This book presents sits, an open-source R package for satellite image time series analysis. The package supports the application of machine learning techniques for classifying image time series obtained from Earth observation data cubes." />


<meta name="author" content="Gilberto Camara" />
<meta name="author" content="Rolf Simoes" />
<meta name="author" content="Felipe Souza" />
<meta name="author" content="Charlotte Peletier" />
<meta name="author" content="Alber Sanchez" />
<meta name="author" content="Pedro R. Andrade" />
<meta name="author" content="Karine Ferreira" />
<meta name="author" content="Gilberto Queiroz" />

<meta name="date" content="2022-07-15" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="This book presents sits, an open-source R package for satellite image time series analysis. The package supports the application of machine learning techniques for classifying image time series obtained from Earth observation data cubes.">

<title>Temporal Convolutional Neural Network (TempCNN) | sits: Satellite Image Time Series Analysis on Earth Observation Data Cubes</title>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#preface">Preface</a>
<ul>
<li><a href="who-this-book-is-for.html#who-this-book-is-for">Who this book is for</a></li>
<li><a href="main-reference-for-sits.html#main-reference-for-sits">Main reference for sits</a></li>
</ul></li>
<li class="has-sub"><a href="setup.html#setup">Setup</a>
<ul>
<li><a href="support-for-gdal-and-proj.html#support-for-gdal-and-proj">Support for GDAL and PROJ</a></li>
<li><a href="installing-the-sits-package.html#installing-the-sits-package">Installing the <code>sits</code> package</a></li>
</ul></li>
<li class="has-sub"><a href="acknowledgements.html#acknowledgements">Acknowledgements</a>
<ul>
<li><a href="funding-sources.html#funding-sources">Funding Sources</a></li>
<li><a href="community-contributions.html#community-contributions">Community Contributions</a></li>
<li><a href="reproducible-papers-used-in-building-sits.html#reproducible-papers-used-in-building-sits">Reproducible papers used in building sits</a></li>
<li><a href="publications-using-sits.html#publications-using-sits">Publications using sits</a></li>
</ul></li>
<li class="has-sub"><a href="1-introduction-to-sits.html#introduction-to-sits"><span class="toc-section-number">1</span> Introduction to SITS</a>
<ul>
<li><a href="how-sits-works.html#how-sits-works">How <code>sits</code> works</a></li>
<li><a href="creating-a-data-cube.html#creating-a-data-cube">Creating a Data Cube</a></li>
<li><a href="the-time-series-table.html#the-time-series-table">The time series table</a></li>
<li><a href="training-a-machine-learning-model.html#training-a-machine-learning-model">Training a machine learning model</a></li>
<li><a href="data-cube-classification.html#data-cube-classification">Data cube classification</a></li>
<li><a href="spatial-smoothing.html#spatial-smoothing">Spatial smoothing</a></li>
<li><a href="labelling-a-probability-data-cube.html#labelling-a-probability-data-cube">Labelling a probability data cube</a></li>
<li><a href="final-remarks.html#final-remarks">Final remarks</a></li>
</ul></li>
<li class="has-sub"><a href="2-earth-observation-data-cubes.html#earth-observation-data-cubes"><span class="toc-section-number">2</span> Earth observation data cubes</a>
<ul>
<li><a href="analysis-ready-data-image-collections.html#analysis-ready-data-image-collections">Analysis-ready data image collections</a></li>
<li><a href="ard-image-collections-handled-by-sits.html#ard-image-collections-handled-by-sits">ARD image collections handled by sits</a></li>
<li><a href="regular-image-data-cubes.html#regular-image-data-cubes">Regular image data cubes</a></li>
<li><a href="creating-data-cubes.html#creating-data-cubes">Creating data cubes</a></li>
<li><a href="assessing-amazon-web-services.html#assessing-amazon-web-services">Assessing Amazon Web Services</a></li>
<li><a href="assessing-microsofts-planetary-computer.html#assessing-microsofts-planetary-computer">Assessing Microsoft’s Planetary Computer</a></li>
<li><a href="assessing-digital-earth-africa.html#assessing-digital-earth-africa">Assessing Digital Earth Africa</a></li>
<li><a href="assessing-the-brazil-data-cube.html#assessing-the-brazil-data-cube">Assessing the Brazil Data Cube</a></li>
<li><a href="defining-a-data-cube-using-ard-local-files.html#defining-a-data-cube-using-ard-local-files">Defining a data cube using ARD local files</a></li>
<li><a href="defining-a-data-cube-using-classified-images.html#defining-a-data-cube-using-classified-images">Defining a data cube using classified images</a></li>
<li><a href="regularizing-data-cubes.html#regularizing-data-cubes">Regularizing data cubes</a></li>
<li><a href="mathematical-operations-on-regular-data-cubes.html#mathematical-operations-on-regular-data-cubes">Mathematical operations on regular data cubes</a></li>
</ul></li>
<li class="has-sub"><a href="3-working-with-time-series.html#working-with-time-series"><span class="toc-section-number">3</span> Working with time series</a>
<ul>
<li><a href="data-structures-for-satellite-time-series.html#data-structures-for-satellite-time-series">Data structures for satellite time series</a></li>
<li><a href="utilities-for-handling-time-series.html#utilities-for-handling-time-series">Utilities for handling time series</a></li>
<li><a href="time-series-visualisation.html#time-series-visualisation">Time series visualisation</a></li>
<li><a href="obtaining-time-series-data-from-data-cubes.html#obtaining-time-series-data-from-data-cubes">Obtaining time series data from data cubes</a></li>
<li class="has-sub"><a href="filtering-techniques-for-time-series.html#filtering-techniques-for-time-series">Filtering techniques for time series</a>
<ul>
<li><a href="filtering-techniques-for-time-series.html#savitzkygolay-filter">Savitzky–Golay filter</a></li>
<li><a href="filtering-techniques-for-time-series.html#whittaker-filter">Whittaker filter</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="4-improving-the-quality-of-training-samples.html#improving-the-quality-of-training-samples"><span class="toc-section-number">4</span> Improving the Quality of Training Samples</a>
<ul>
<li><a href="introduction.html#introduction">Introduction</a></li>
<li><a href="hierachical-clustering-for-sample-quality-control.html#hierachical-clustering-for-sample-quality-control">Hierachical clustering for sample quality control</a></li>
<li class="has-sub"><a href="using-self-organizing-maps-for-sample-quality-control.html#using-self-organizing-maps-for-sample-quality-control">Using self-organizing maps for sample quality control</a>
<ul>
<li><a href="using-self-organizing-maps-for-sample-quality-control.html#som-based-quality-assessment-creating-the-som-map">SOM-based quality assessment: creating the SOM map</a></li>
<li><a href="using-self-organizing-maps-for-sample-quality-control.html#som-based-quality-assessment-measuring-confusion-between-labels">SOM-based quality assessment: measuring confusion between labels</a></li>
<li><a href="using-self-organizing-maps-for-sample-quality-control.html#som-based-quality-assessment-part-3-using-probabilities-to-detect-noisy-samples">SOM-based quality assessment part 3: using probabilities to detect noisy samples</a></li>
</ul></li>
<li><a href="reducing-sample-imbalance.html#reducing-sample-imbalance">Reducing sample imbalance</a></li>
<li><a href="conclusion.html#conclusion">Conclusion</a></li>
</ul></li>
<li class="has-sub"><a href="5-machine-learning-for-data-cubes-using-the-sits-package.html#machine-learning-for-data-cubes-using-the-sits-package"><span class="toc-section-number">5</span> Machine Learning for Data Cubes using the SITS package</a>
<ul>
<li><a href="machine-learning-classification.html#machine-learning-classification">Machine learning classification</a></li>
<li><a href="visualizing-sample-patterns.html#visualizing-sample-patterns">Visualizing Sample Patterns</a></li>
<li><a href="common-interface-to-machine-learning-and-deep-learning-models.html#common-interface-to-machine-learning-and-deep-learning-models">Common interface to machine learning and deep learning models</a></li>
<li><a href="random-forests.html#random-forests">Random forests</a></li>
<li><a href="support-vector-machines.html#support-vector-machines">Support Vector Machines</a></li>
<li><a href="extreme-gradient-boosting.html#extreme-gradient-boosting">Extreme Gradient Boosting</a></li>
<li><a href="deep-learning-using-multilayer-perceptrons.html#deep-learning-using-multilayer-perceptrons">Deep learning using multilayer perceptrons</a></li>
<li><a href="temporal-convolutional-neural-network-tempcnn.html#temporal-convolutional-neural-network-tempcnn">Temporal Convolutional Neural Network (TempCNN)</a></li>
<li><a href="residual-1d-cnn-networks-resnet.html#residual-1d-cnn-networks-resnet">Residual 1D CNN Networks (ResNet)</a></li>
<li><a href="attention-based-models.html#attention-based-models">Attention-based models</a></li>
<li><a href="model-tuning.html#model-tuning">Model tuning</a></li>
<li><a href="considerations-on-model-choice.html#considerations-on-model-choice">Considerations on model choice</a></li>
</ul></li>
<li class="has-sub"><a href="classification-of-images-in-data-cubes-using-satellite-image-time-series.html#classification-of-images-in-data-cubes-using-satellite-image-time-series">Classification of Images in Data Cubes using Satellite Image Time Series</a>
<ul>
<li><a href="training-the-classification-model.html#training-the-classification-model">Training the classification model</a></li>
<li><a href="building-the-data-cube.html#building-the-data-cube">Building the data cube</a></li>
<li><a href="classification-using-parallel-processing.html#classification-using-parallel-processing">Classification using parallel processing</a></li>
<li class="has-sub"><a href="post-classification-smoothing.html#post-classification-smoothing">Post-classification smoothing</a>
<ul>
<li><a href="post-classification-smoothing.html#bayesian-smoothing">Bayesian smoothing</a></li>
</ul></li>
<li class="has-sub"><a href="bilateral-smoothing.html#bilateral-smoothing">Bilateral smoothing</a>
<ul>
<li><a href="bilateral-smoothing.html#how-parallel-processing-works-in-sits"><span class="toc-section-number">5.0.1</span> How parallel processing works in <code class="unnumbered">sits</code></a></li>
<li><a href="bilateral-smoothing.html#processing-time-estimates">Processing time estimates</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="6-validation-and-accuracy-measurements-in-sits.html#validation-and-accuracy-measurements-in-sits"><span class="toc-section-number">6</span> Validation and accuracy measurements in SITS</a>
<ul>
<li><a href="6.1-case-study-used-in-this-chapter.html#case-study-used-in-this-chapter"><span class="toc-section-number">6.1</span> Case study used in this Chapter</a></li>
<li><a href="6.2-validation-techniques.html#validation-techniques"><span class="toc-section-number">6.2</span> Validation techniques</a></li>
<li><a href="6.3-comparing-different-machine-learning-methods-using-k-fold-validation.html#comparing-different-machine-learning-methods-using-k-fold-validation"><span class="toc-section-number">6.3</span> Comparing different machine learning methods using k-fold validation</a></li>
<li class="has-sub"><a href="6.4-accuracy-assessment.html#accuracy-assessment"><span class="toc-section-number">6.4</span> Accuracy assessment</a>
<ul>
<li><a href="6.4-accuracy-assessment.html#time-series"><span class="toc-section-number">6.4.1</span> Time series</a></li>
<li><a href="6.4-accuracy-assessment.html#classified-images"><span class="toc-section-number">6.4.2</span> Classified images</a></li>
</ul></li>
</ul></li>
<li><a href="uncertainty-and-active-learning.html#uncertainty-and-active-learning">Uncertainty and active learning</a></li>
<li class="has-sub"><a href="7-design-and-extensibility-considerations.html#design-and-extensibility-considerations"><span class="toc-section-number">7</span> Design and extensibility considerations</a>
<ul>
<li><a href="7.1-design-decisions.html#design-decisions"><span class="toc-section-number">7.1</span> Design decisions</a></li>
</ul></li>
<li class="has-sub"><a href="technical-annex.html#technical-annex">Technical Annex</a>
<ul>
<li class="has-sub"><a href="7.2-bayesian-smoothing-1.html#bayesian-smoothing-1"><span class="toc-section-number">7.2</span> Bayesian smoothing</a>
<ul>
<li><a href="7.2-bayesian-smoothing-1.html#derivation-of-bayesian-parameters-for-spatiotemporal-smoothing"><span class="toc-section-number">7.2.1</span> Derivation of bayesian parameters for spatiotemporal smoothing</a></li>
</ul></li>
<li><a href="7.3-bilateral-smoothing-1.html#bilateral-smoothing-1"><span class="toc-section-number">7.3</span> Bilateral smoothing</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="temporal-convolutional-neural-network-tempcnn" class="section level2 unnumbered">
<h2>Temporal Convolutional Neural Network (TempCNN)</h2>
<p>Convolutional neural networks (CNN) are a variety of deep learning methods where a convolution filter (sliding window) is applied to the input data. In the case of time series, a 1D CNN works by applying a moving window to the series. Using convolution filters is a way to incorporate temporal autocorrelation information in the classification. The result of the convolution is another time series. Russwurm and Körner <span class="citation"><a href="#ref-Russwurm2017" role="doc-biblioref">[45]</a></span> state that the use of 1D-CNN for time series classification improves on the use of multilayer perceptrons, since the classifier is able to represent temporal relationships; also, the convolution window makes the classifier more robust to moderate noise, e.g. intermittent presence of clouds.</p>
<p>The use of 1D CNNs for satellite image time series classification is proposed by Pelletier et al <span class="citation"><a href="#ref-Pelletier2019" role="doc-biblioref">[29]</a></span>. The TempCNN architecture has three 1D convolutional layers, and a final softmax layer for classification (see figure). The authors use a combination of different methods to avoid overfitting and reduce the vanishing gradient effect, including dropout, regularization, and batch normalisation. In the tempCNN paper <span class="citation"><a href="#ref-Pelletier2019" role="doc-biblioref">[29]</a></span>, the authors compare favorably their model with the Recurrent Neural Network proposed by Russwurm and Körner <span class="citation"><a href="#ref-Russwurm2018" role="doc-biblioref">[46]</a></span> for land use classification. The figure below shows the architecture of the tempCNN model.</p>
<div class="figure" style="text-align: center">
<img src="images/tempcnn.png" alt="Structure of tempCNN architecture (source: Pelletier et al.(2019))" width="90%" />
<p class="caption">
Structure of tempCNN architecture (source: Pelletier et al.(2019))
</p>
</div>
<p>The function <code>sits_tempcnn()</code> implements the model. The parameter <code>cnn_layers</code> controls the number of 1D-CNN layers and the size of the filters applied at each layer; the default values are three CNNs with 128 units. The parameter <code>cnn_kernels</code> indicates the size of the convolution kernels; the default are kernels of size 7. Activation for all 1D-CNN layers uses the “relu” function. The dropout rates for each 1D-CNN layer are controlled individually by the parameter <code>cnn_dropout_rates</code>. The <code>validation_split</code> controls the size of the test set, relative to the full data set. We recommend to set aside at least 20% of the samples for validation.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torchopt)</span>
<span id="cb72-2"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="co"># train a machine learning model using tempCNN</span></span>
<span id="cb72-3"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-3" aria-hidden="true" tabindex="-1"></a>tempcnn_model <span class="ot">&lt;-</span> <span class="fu">sits_train</span>(</span>
<span id="cb72-4"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-4" aria-hidden="true" tabindex="-1"></a>  samples_matogrosso_mod13q1,</span>
<span id="cb72-5"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sits_tempcnn</span>(</span>
<span id="cb72-6"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer            =</span> torchopt<span class="sc">::</span>optim_adamw,</span>
<span id="cb72-7"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">cnn_layers           =</span> <span class="fu">c</span>(<span class="dv">128</span>, <span class="dv">128</span>, <span class="dv">128</span>),</span>
<span id="cb72-8"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">cnn_kernels          =</span> <span class="fu">c</span>(<span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>),</span>
<span id="cb72-9"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">cnn_dropout_rates    =</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>),</span>
<span id="cb72-10"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs               =</span> <span class="dv">100</span>,</span>
<span id="cb72-11"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size           =</span> <span class="dv">64</span>,</span>
<span id="cb72-12"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split     =</span> <span class="fl">0.2</span>,</span>
<span id="cb72-13"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose              =</span> <span class="cn">FALSE</span></span>
<span id="cb72-14"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-14" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb72-15"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb72-16"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-17"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-17" aria-hidden="true" tabindex="-1"></a><span class="co"># show training evolution</span></span>
<span id="cb72-18"><a href="temporal-convolutional-neural-network-tempcnn.html#cb72-18" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tempcnn_model)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="sitsbook_files/figure-html/unnamed-chunk-79-1.png" alt="Training evolution of TempCNN model." width="70%" />
<p class="caption">
Training evolution of TempCNN model.
</p>
</div>
<p>Then, we classify a 16-year time series using the TempCNN model.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="temporal-convolutional-neural-network-tempcnn.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Classify using TempCNN model and plot the result</span></span>
<span id="cb73-2"><a href="temporal-convolutional-neural-network-tempcnn.html#cb73-2" aria-hidden="true" tabindex="-1"></a>class <span class="ot">&lt;-</span> point_mt_6bands <span class="sc">%&gt;%</span></span>
<span id="cb73-3"><a href="temporal-convolutional-neural-network-tempcnn.html#cb73-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sits_select</span>(<span class="at">bands =</span> <span class="fu">c</span>(<span class="st">&quot;NDVI&quot;</span>, <span class="st">&quot;EVI&quot;</span>, <span class="st">&quot;NIR&quot;</span>, <span class="st">&quot;MIR&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb73-4"><a href="temporal-convolutional-neural-network-tempcnn.html#cb73-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sits_classify</span>(tempcnn_model) <span class="sc">%&gt;%</span></span>
<span id="cb73-5"><a href="temporal-convolutional-neural-network-tempcnn.html#cb73-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="at">bands =</span> <span class="fu">c</span>(<span class="st">&quot;NDVI&quot;</span>, <span class="st">&quot;EVI&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="sitsbook_files/figure-html/unnamed-chunk-80-1.png" alt="Classification of time series using TempCNN." width="70%" />
<p class="caption">
Classification of time series using TempCNN.
</p>
</div>
<p>The result has important differences from the previous ones. The TempCNN model indicates the “Soy_Cotton” class as the most likely one in 2004. While this result is likely to be wrong, it shows that the time series for year 2004 is different from those of “Forest” and “Pasture” classes. One possible explanation is that there was forest degradation in 2004, leading to a signature that is a mix of forest and bare soil. In this case, users could consider improving the training data by including samples that represent forest degradation. In our experience, TempCNN models are a reliable way for classifying image time series <span class="citation"><a href="#ref-Simoes2021" role="doc-biblioref">[47]</a></span>. Recent work which compares different models also provides evidence of that TempCNN models have satisfactory behavior, especially in the case of crop classes <span class="citation"><a href="#ref-Russwurm2020" role="doc-biblioref">[32]</a></span>.</p>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body">
<div id="ref-Pelletier2019" class="csl-entry">
<div class="csl-left-margin">[29] </div><div class="csl-right-inline">C. Pelletier, G. I. Webb, and F. Petitjean, <span>“Temporal <span>Convolutional Neural Network</span> for the <span>Classification</span> of <span>Satellite Image Time Series</span>,”</span> <em>Remote Sensing</em>, vol. 11, no. 5, 2019.</div>
</div>
<div id="ref-Russwurm2020" class="csl-entry">
<div class="csl-left-margin">[32] </div><div class="csl-right-inline">M. Rußwurm, C. Pelletier, M. Zollner, S. Lefèvre, and M. Körner, <span>“<span>BreizhCrops</span>: <span>A Time Series Dataset</span> for <span>Crop Type Mapping</span>,”</span> 2020.</div>
</div>
<div id="ref-Russwurm2017" class="csl-entry">
<div class="csl-left-margin">[45] </div><div class="csl-right-inline">M. Rußwurm and M. Korner, <span>“Temporal vegetation modelling using long short-term memory networks for crop identification from medium-resolution multi-spectral satellite images,”</span> in <em>Proceedings of the <span>IEEE Conference</span> on <span>Computer Vision</span> and <span>Pattern Recognition Workshops</span></em>, 2017, pp. 11–19.</div>
</div>
<div id="ref-Russwurm2018" class="csl-entry">
<div class="csl-left-margin">[46] </div><div class="csl-right-inline">M. Russwurm and M. Korner, <span>“Multi-temporal land cover classification with sequential recurrent encoders,”</span> <em>ISPRS International Journal of Geo-Information</em>, vol. 7, no. 4, p. 129, 2018.</div>
</div>
<div id="ref-Simoes2021" class="csl-entry">
<div class="csl-left-margin">[47] </div><div class="csl-right-inline">R. Simoes <em>et al.</em>, <span>“Satellite <span>Image Time Series Analysis</span> for <span>Big Earth Observation Data</span>,”</span> <em>Remote Sensing</em>, vol. 13, no. 13, p. 2428, 2021, doi: <a href="https://doi.org/10.3390/rs13132428">10.3390/rs13132428</a>.</div>
</div>
</div>
<p style="text-align: center;">
<a href="deep-learning-using-multilayer-perceptrons.html"><button class="btn btn-default">Previous</button></a>
<a href="residual-1d-cnn-networks-resnet.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
